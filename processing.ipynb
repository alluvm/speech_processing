{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dc767c-4feb-47e4-b85e-e77bd108e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: noisereduce in /opt/software/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: librosa in /opt/software/lib/python3.9/site-packages (from noisereduce) (0.9.1)\n",
      "Requirement already satisfied: tqdm in /opt/software/lib/python3.9/site-packages (from noisereduce) (4.61.2)\n",
      "Requirement already satisfied: matplotlib in /opt/software/lib/python3.9/site-packages (from noisereduce) (3.5.1)\n",
      "Requirement already satisfied: scipy in /opt/software/lib/python3.9/site-packages (from noisereduce) (1.8.0)\n",
      "Requirement already satisfied: numpy in /opt/software/lib/python3.9/site-packages (from noisereduce) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (1.1.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (0.55.1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (5.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (0.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (1.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (21.3)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (2.1.9)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (0.10.3.post1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (1.6.0)\n",
      "Requirement already satisfied: setuptools in /opt/software/lib/python3.9/site-packages (from numba>=0.45.1->librosa->noisereduce) (49.6.0.post20210108)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/software/lib/python3.9/site-packages (from numba>=0.45.1->librosa->noisereduce) (0.38.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/software/lib/python3.9/site-packages (from packaging>=20.0->librosa->noisereduce) (3.0.7)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/software/lib/python3.9/site-packages (from pooch>=1.0->librosa->noisereduce) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/software/lib/python3.9/site-packages (from pooch>=1.0->librosa->noisereduce) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/software/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/software/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/software/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/software/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.3 in /opt/software/lib/python3.9/site-packages (from resampy>=0.2.2->librosa->noisereduce) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/software/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa->noisereduce) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/software/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/software/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.20)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (4.29.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (1.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install noisereduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft, istft\n",
    "from scipy.fft import fft, fftshift, fftfreq, ifft, ifftshift, dct\n",
    "import sklearn as sk\n",
    "import scipy as sc\n",
    "import scipy.signal as scp\n",
    "import numpy.random as rnd\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "import noisereduce as nr\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7856c2-c42b-4dd3-ac4f-973436d2246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2148/1501718462.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, sig = wavfile.read(\"./data/1/Audio Track.wav\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4122096400>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variables\n",
    "data_path = \"./data/1/\"\n",
    "data_folder = os.getcwd() + \"/data\"\n",
    "fs = 48000\n",
    "\n",
    "fs, sig = wavfile.read(\"./data/1/Audio Track.wav\")\n",
    "print(fs)\n",
    "plt.plot(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09d7bc4-45f4-4d54-a83c-b8194cd242d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "import librosa\n",
    "def create_dataset(root):\n",
    "    \"\"\"\n",
    "    Apply function to all files under root\n",
    "    returns 1 if succesfull, -1 if not.\n",
    "    \"\"\"\n",
    "    data    = []\n",
    "    labels  = []\n",
    "    lengths = []\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        for filename in filenames:\n",
    "\n",
    "            label = dirpath[-1]\n",
    "            _ , signal   = wavfile.read(f\"{dirpath}/{filename}\")\n",
    "            \n",
    "            \n",
    "            cleaned       = clean_data(signal)\n",
    "            \n",
    "            features   = MFCC(cleaned, fs)\n",
    "            features[features!=features] = 0\n",
    "            features   = np.insert(features, 0, len(cleaned))\n",
    "\n",
    "            feat_noisy = MFCC(generate_noisy(cleaned, 0.05), fs)\n",
    "            feat_noisy[feat_noisy!=feat_noisy] = 0\n",
    "            feat_noisy = np.insert(feat_noisy, 0, len(cleaned))\n",
    "\n",
    "            feat_noisy2 = MFCC(generate_noisy(cleaned, 0.1), fs)\n",
    "            feat_noisy2[feat_noisy2!=feat_noisy2] = 0\n",
    "            feat_noisy2 = np.insert(feat_noisy, 0, len(cleaned))\n",
    "            \n",
    "            if label != \"0\":              \n",
    "                data.append(features.flatten())\n",
    "                labels.append(label)\n",
    "                \n",
    "                data.append(feat_noisy.flatten())\n",
    "                labels.append(label)\n",
    "                \n",
    "                data.append(feat_noisy2.flatten())\n",
    "                labels.append(label)\n",
    "\n",
    "\n",
    "            \n",
    "    df = pd.DataFrame(data, index=labels).sort_index()\n",
    "    df[df!=df] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_noisy(data, ratio):\n",
    "    \"\"\"\n",
    "    Generate noisy variant of data.\n",
    "    noise is additive and normally distributed\n",
    "    \"\"\"\n",
    "    return data + rnd.normal(0,1,len(data)) * max(abs(data)) * ratio\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    remove silent spaces and noise\n",
    "    \"\"\"\n",
    "    return data[abs(data) > abs(data).mean()*0.05] / max(abs(data))\n",
    "    \n",
    "def read_wav(path):\n",
    "    \"\"\"\n",
    "    Reads wav file\n",
    "    Returns time and signal vectors\n",
    "    \"\"\"\n",
    "    fs, signal = wavfile.read(path)\n",
    "    t = np.arange(0,len(signal)/fs, 1/fs)\n",
    "    return [t, signal]\n",
    "\n",
    "def remove_noise(data):\n",
    "    \"\"\"\n",
    "    Simple function to remove the noise from the signal data\n",
    "    \"\"\"\n",
    "    return nr.reduce_noise(y=data, sr=fs)\n",
    "\n",
    "def predict_input(audioname, model, scaler):\n",
    "    _, test_sample = wavfile.read(f\"./predict/{audioname}.wav\")\n",
    "    clean = clean_data(test_sample)\n",
    "    features = MFCC(clean, fs)\n",
    "    features[features!=features] = 0\n",
    "    features = np.insert(features, 0, len(clean))\n",
    "    features = np.pad(features, (0, 1214-len(features)))\n",
    "    features = np.tile(features, (10,1))\n",
    "    features = scaler.transform(features)\n",
    "\n",
    "    pred = model.predict(features)\n",
    "    vals, counts = np.unique(pred, return_counts = True)\n",
    "    return vals[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0083caf0-9cb1-47ad-ba18-54cece73c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "# http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "\n",
    "def mel(f):\n",
    "    \"\"\"\n",
    "    Transform to mel space\n",
    "    \"\"\" \n",
    "    return 1127*np.log(1+f/700)\n",
    "\n",
    "def imel(m):\n",
    "    \"\"\"\n",
    "    Transform from mel space to frequency domain\n",
    "    \"\"\"\n",
    "    return 700*(np.exp(m/1127) - 1)\n",
    "\n",
    "def MFCC(signal, fs):\n",
    "    \"\"\"\n",
    "    HAS TO BE DEBUGGED\n",
    "    Compute mel frequency coefficients\n",
    "    \"\"\"\n",
    "    # compute spectrum for frames of 25 ms with 10 ms overlaps\n",
    "    Nfft = 2048\n",
    "    f, t, Z = stft(x=signal, fs=fs, window='hann', nperseg=fs*25e-3, noverlap=fs*10e-3, nfft=Nfft)\n",
    "    Nf = len(t) # number of frames in signal\n",
    "    Ncut = int(np.ceil(Nfft/6)) # 342 point spectrum\n",
    "    # turn each FFT window into power spectrum by scaling\n",
    "    P = np.zeros((Nf,Ncut))\n",
    "    for n in range(Nf):\n",
    "        Fcut = Z[:Ncut,n] # compute the 342 point power spectrum\n",
    "        P[n] = abs(Fcut)**2/Ncut\n",
    "    \n",
    "    # upper and lower frequency bounds in Hz converted to Mel scale\n",
    "    upperHz = 8000\n",
    "    lowerHz = 300\n",
    "    upperMel = mel(upperHz)\n",
    "    lowerMel = mel(lowerHz)\n",
    "    m = np.linspace(lowerMel,upperMel,28) # mel filterbank\n",
    "    h = imel(m) # filterbank in frequency domain\n",
    "    f = np.floor((Nfft+1)*h/fs) # filterbank as FFT bin indices\n",
    "    f = f.astype(int)\n",
    "    \n",
    "    # construct filters in filterbank\n",
    "    mfilters = np.zeros((26,342))\n",
    "    for n in range(26):\n",
    "        for i in range(len(f)):\n",
    "            if i != 0 and i != len(f)-1:\n",
    "                for iless in range(f[i]-f[i-1]):\n",
    "                    mfilters[n,f[i-1]+iless] = iless/(f[i]-f[i-1])\n",
    "                for imore in range(f[i+1]-f[i]):\n",
    "                    mfilters[n,f[i]+imore] = 1-imore/(f[i+1]-f[i])\n",
    "    \n",
    "    M = np.zeros((Nf,26))\n",
    "    # filter data with filterbank\n",
    "    for n in range(Nf):\n",
    "        for c in range(26):\n",
    "            M[n,c] = sum(mfilters[c]*P[n])\n",
    "    \n",
    "    # take the log discrete cosine transform of frame spectra\n",
    "    mfcc = np.zeros((Nf,12))\n",
    "    for n in range(Nf):\n",
    "        mfcc[n] = dct(np.log(M[n]), type=3)[1:13]\n",
    "    \n",
    "    # return ndarray with rows representing timeframes and \n",
    "    return mfcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecfd19-fa90-4164-9cae-26c67d41bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2148/65687103.py:16: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  _ , signal   = wavfile.read(f\"{dirpath}/{filename}\")\n",
      "/tmp/ipykernel_2148/3257212282.py:61: RuntimeWarning: divide by zero encountered in log\n",
      "  mfcc[n] = dct(np.log(M[n]), type=3)[1:13]\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(data_folder)\n",
    "\n",
    "labels = dataset.index\n",
    "features = dataset.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cb53c-10b7-4559-851e-69b5e6d4ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "random_state = 1\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "X = dataset.values\n",
    "y = dataset.index\n",
    "\n",
    "results = []\n",
    "\n",
    "labels = [str(i) for i in range(1,10)]\n",
    "\n",
    "\n",
    "cms = np.zeros(shape=(9,9))\n",
    "clrs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.33,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "    \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "model = RandomForestClassifier(n_estimators=300,\n",
    "                                   max_features=\"log2\",\n",
    "                                   criterion=\"gini\",\n",
    "                                   class_weight=\"balanced\",\n",
    "                                   random_state=random_state)\n",
    "    \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "     \n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "cms += cm\n",
    "clrs.append(classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "results.append(cross_val_score(model, X, y, cv=5).mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62a6e3-f422-4a2a-8de9-de8f5bb51d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results)\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.title(\"Classifier 5 fold cv scores\")\n",
    "#plt.savefig(\"scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6c170-070b-4d15-a516-b0b6ce6d9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\"\"\"\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1-score = (2*recall*precision)/(recall+precision)\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\"\"\"\n",
    "# Normalize confusion matrix\n",
    "cms = cms / cms.sum(axis=0)\n",
    "\n",
    "plt.subplots(figsize=(10,5))\n",
    "sns.heatmap(cms, annot=True,\n",
    "           fmt=\".2f\",\n",
    "           xticklabels = labels,\n",
    "           yticklabels = labels)\n",
    "\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.savefig(\"CM\")\n",
    "plt.show()\n",
    "\n",
    "print(clrs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc04b8f8-5515-4778-a2ce-c9d1019a159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This audio file is from a person whose voice was not used to train the model\n",
    "\n",
    "filename = \"kahdeksan_r\"\n",
    "audio_sample = read_wav(f\"./predict/{filename}.wav\")\n",
    "\n",
    "prediction = predict_input(filename,model,scaler)\n",
    "print(f\"The number you said was {prediction}\")\n",
    "\n",
    "Audio(audio_sample, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6ad28-09c8-47d2-909a-91b05cfaa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sample is from someone whose voice was used to train the model\n",
    "\n",
    "filename = \"seitsem√§n_t\"\n",
    "audio_sample = read_wav(f\"./predict/{filename}.wav\")\n",
    "\n",
    "prediction = predict_input(filename,model,scaler)\n",
    "print(f\"The number you said was {prediction}\")\n",
    "\n",
    "Audio(audio_sample, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475f167-b733-4b81-a60a-a5cea259208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This audio file is from a person whose voice was not used to train the model\n",
    "# This fails\n",
    "\n",
    "filename = \"viisi_r\"\n",
    "audio_sample = read_wav(f\"./predict/{filename}.wav\")\n",
    "\n",
    "prediction = predict_input(filename,model,scaler)\n",
    "print(f\"The number you said was {prediction}\")\n",
    "\n",
    "Audio(audio_sample, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e9377-ef98-4106-bb14-e8b482e5097c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a843585-3163-4b69-8927-2dcef3aadff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
