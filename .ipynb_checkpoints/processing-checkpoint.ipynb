{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dc767c-4feb-47e4-b85e-e77bd108e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: noisereduce in /opt/software/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: librosa in /opt/software/lib/python3.9/site-packages (from noisereduce) (0.9.1)\n",
      "Requirement already satisfied: tqdm in /opt/software/lib/python3.9/site-packages (from noisereduce) (4.61.2)\n",
      "Requirement already satisfied: scipy in /opt/software/lib/python3.9/site-packages (from noisereduce) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /opt/software/lib/python3.9/site-packages (from noisereduce) (3.5.1)\n",
      "Requirement already satisfied: numpy in /opt/software/lib/python3.9/site-packages (from noisereduce) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (1.0.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (5.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (0.2.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (1.6.0)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (2.1.9)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (0.10.3.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (1.1.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (0.55.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/software/lib/python3.9/site-packages (from librosa->noisereduce) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/software/lib/python3.9/site-packages (from numba>=0.45.1->librosa->noisereduce) (49.6.0.post20210108)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/software/lib/python3.9/site-packages (from numba>=0.45.1->librosa->noisereduce) (0.38.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/software/lib/python3.9/site-packages (from packaging>=20.0->librosa->noisereduce) (3.0.7)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/software/lib/python3.9/site-packages (from pooch>=1.0->librosa->noisereduce) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/software/lib/python3.9/site-packages (from pooch>=1.0->librosa->noisereduce) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/software/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/software/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/software/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/software/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.3 in /opt/software/lib/python3.9/site-packages (from resampy>=0.2.2->librosa->noisereduce) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/software/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa->noisereduce) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/software/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/software/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/software/lib/python3.9/site-packages (from matplotlib->noisereduce) (0.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install noisereduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft, istft\n",
    "from scipy.fft import fft, fftshift, fftfreq, ifft, ifftshift, dct\n",
    "import sklearn as sk\n",
    "import scipy as sc\n",
    "import scipy.signal as scp\n",
    "import numpy.random as rnd\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "import noisereduce as nr\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7856c2-c42b-4dd3-ac4f-973436d2246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "data_path = \"./data/9/\"\n",
    "data_folder = os.getcwd() + \"/data\"\n",
    "fs = 48000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c09d7bc4-45f4-4d54-a83c-b8194cd242d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "import librosa\n",
    "def create_dataset(root):\n",
    "    \"\"\"\n",
    "    Apply function to all files under root\n",
    "    returns 1 if succesfull, -1 if not.\n",
    "    \"\"\"\n",
    "    data    = []\n",
    "    labels  = []\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        for filename in filenames:\n",
    "\n",
    "            label = dirpath[-1]\n",
    "            _ , signal   = wavfile.read(f\"{dirpath}/{filename}\")\n",
    "                        \n",
    "            cleaned    = clean_data2(signal)\n",
    "            mfcc       = np.array(MFCC(cleaned, fs))\n",
    "            \n",
    "            features   = []\n",
    "            mean_feat  = mfcc.mean(axis=0)\n",
    "            std_feat   = mfcc.std(axis=0)\n",
    "            var_feat   = mfcc.var(axis=0)\n",
    "                        \n",
    "            features.extend(std_feat)\n",
    "           # features.extend(var_feat)\n",
    "            #features.extend(mean_feat)\n",
    "            features.extend(mfcc.flatten())\n",
    "            features[features!=features] = 0\n",
    "            features   = np.insert(features, 0, len(cleaned))\n",
    "        \n",
    "            if label != \"0\":              \n",
    "                data.append(features)\n",
    "                labels.append(label)\n",
    "\n",
    "\n",
    "            \n",
    "    df = pd.DataFrame(data, index=labels).sort_index()\n",
    "    df[df!=df] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_noisy(data, ratio):\n",
    "    \"\"\"\n",
    "    Generate noisy variant of data.\n",
    "    noise is additive and normally distributed\n",
    "    \"\"\"\n",
    "    return data + rnd.normal(0,1,len(data)) * max(abs(data)) * ratio\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    remove silent spaces and noise\n",
    "    \"\"\"\n",
    "    wlen = int(0.03*fs)\n",
    "    hop  = int(wlen/2) \n",
    "        \n",
    "    f, t, X = stft(x=data,\n",
    "               fs=fs,\n",
    "               nperseg=wlen,\n",
    "               noverlap=hop,\n",
    "               return_onesided=True)\n",
    "\n",
    "    PSD = abs(X)**2\n",
    "    \n",
    "    coef = 10\n",
    "    mean = coef*10**(1/10*np.mean(10*np.log10(PSD),1))\n",
    "    \n",
    "    PSDN_est = np.ones(PSD.shape)*mean[:,None]\n",
    "    g = (PSD-PSDN_est)/PSD\n",
    "    \n",
    "    g[g<0] = 10**(-32)\n",
    "    g = np.sqrt(g)\n",
    "    S = X*g\n",
    "    t_p, processed = istft(S, fs=fs, nperseg=wlen, noverlap=hop)\n",
    "    \n",
    "    trimmed, _ = librosa.effects.trim(processed, top_db=25)\n",
    "\n",
    "    return trimmed\n",
    "    \n",
    "def read_wav(path):\n",
    "    \"\"\"\n",
    "    Reads wav file\n",
    "    Returns time and signal vectors\n",
    "    \"\"\"\n",
    "    fs, signal = wavfile.read(path)\n",
    "    t = np.arange(0,len(signal)/fs, 1/fs)\n",
    "    return [t, signal]\n",
    "\n",
    "def remove_noise(data):\n",
    "    \"\"\"\n",
    "    Simple function to remove the noise from the signal data\n",
    "    \"\"\"\n",
    "    return nr.reduce_noise(y=data, sr=fs)\n",
    "\n",
    "def predict_input(audioname, model, scaler, length):\n",
    "    _, test_sample = wavfile.read(f\"./predict/{audioname}.wav\")\n",
    "    clean = clean_data(test_sample)\n",
    "    features = MFCC(clean, fs)\n",
    "    features[features!=features] = 0\n",
    "    features = np.insert(features, 0, len(clean))\n",
    "    features = np.pad(features, (0, length-len(features)))\n",
    "    features = np.tile(features, (10,1))\n",
    "    features = scaler.transform(features)\n",
    "\n",
    "    pred = model.predict(X=features)\n",
    "    vals, counts = np.unique(pred, return_counts = True)\n",
    "    return vals[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0083caf0-9cb1-47ad-ba18-54cece73c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "# http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "\n",
    "def mel(f):\n",
    "    \"\"\"\n",
    "    Transform to mel space\n",
    "    \"\"\" \n",
    "    return 1127*np.log(1+f/700)\n",
    "\n",
    "def imel(m):\n",
    "    \"\"\"\n",
    "    Transform from mel space to frequency domain\n",
    "    \"\"\"\n",
    "    return 700*(np.exp(m/1127) - 1)\n",
    "\n",
    "def MFCC(signal, fs):\n",
    "    np.seterr(divide='ignore')\n",
    "    \"\"\"\n",
    "    Compute mel frequency coefficients\n",
    "    \"\"\"\n",
    "    # compute spectrum for frames of 25 ms with 10 ms overlaps\n",
    "    Nfft = 2048\n",
    "    f, t, Z = stft(x=signal, fs=fs, window='hann', nperseg=fs*25e-3, noverlap=fs*10e-3, nfft=Nfft)\n",
    "    Nf = len(t) # number of frames in signal\n",
    "    Ncut = int(np.ceil(Nfft/6)) # 342 point spectrum\n",
    "    # turn each FFT window into power spectrum by scaling\n",
    "    P = np.zeros((Nf,Ncut))\n",
    "    for n in range(Nf):\n",
    "        Fcut = Z[:Ncut,n] # compute the 342 point power spectrum\n",
    "        P[n] = abs(Fcut)**2/Ncut\n",
    "    \n",
    "    # upper and lower frequency bounds in Hz converted to Mel scale\n",
    "    upperHz = 8000\n",
    "    lowerHz = 300\n",
    "    upperMel = mel(upperHz)\n",
    "    lowerMel = mel(lowerHz)\n",
    "    m = np.linspace(lowerMel,upperMel,28) # mel filterbank\n",
    "    h = imel(m) # filterbank in frequency domain\n",
    "    f = np.floor((Nfft+1)*h/fs) # filterbank as FFT bin indices\n",
    "    f = f.astype(int)\n",
    "    \n",
    "    # construct filters in filterbank\n",
    "    mfilters = np.zeros((26,342))\n",
    "    for n in range(26):\n",
    "        for i in range(len(f)):\n",
    "            if i != 0 and i != len(f)-1:\n",
    "                for iless in range(f[i]-f[i-1]):\n",
    "                    mfilters[n,f[i-1]+iless] = iless/(f[i]-f[i-1])\n",
    "                for imore in range(f[i+1]-f[i]):\n",
    "                    mfilters[n,f[i]+imore] = 1-imore/(f[i+1]-f[i])\n",
    "    \n",
    "    M = np.zeros((Nf,26))\n",
    "    # filter data with filterbank\n",
    "    for n in range(Nf):\n",
    "        for c in range(26):\n",
    "            M[n,c] = sum(mfilters[c]*P[n])\n",
    "    \n",
    "    # take the log discrete cosine transform of frame spectra\n",
    "    mfcc = np.zeros((Nf,12))\n",
    "    for n in range(Nf):\n",
    "        mfcc[n] = dct(np.log(M[n]), type=3)[1:13]\n",
    "    \n",
    "    # compute mfcc delta functions of first and second degree\n",
    "    delta = np.zeros((Nf,12))\n",
    "    deltadelta = np.zeros((Nf,12))\n",
    "    for n in range(Nf-1):\n",
    "        delta[n+1] = mfcc[n+1] - mfcc[n]\n",
    "        deltadelta[n+1] = delta[n+1] - delta[n]\n",
    "    \n",
    "    # return ndarray with rows representing timeframes and columns representing the 12 coefficients\n",
    "    # (or change in coefficients)\n",
    "    return mfcc, delta, deltadelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecfd19-fa90-4164-9cae-26c67d41bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_670/2836398718.py:15: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  _ , signal   = wavfile.read(f\"{dirpath}/{filename}\")\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(data_folder)\n",
    "\n",
    "labels = dataset.index\n",
    "features = dataset.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cb53c-10b7-4559-851e-69b5e6d4ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing   import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble        import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics         import confusion_matrix, classification_report\n",
    "\n",
    "random_state = 42\n",
    "encoder      = LabelEncoder()\n",
    "\n",
    "X = dataset.values\n",
    "y = dataset.index\n",
    "\n",
    "labels  = [str(i) for i in range(1,10)]\n",
    "\n",
    "\n",
    "cms = np.zeros(shape=(9,9))\n",
    "clrs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "    \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "model =  ExtraTreesClassifier(n_estimators=480,\n",
    "                                   max_features=\"sqrt\",\n",
    "                                   criterion=\"entropy\",\n",
    "                                   class_weight=\"balanced\",\n",
    "                                   random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "     \n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "cms += cm\n",
    "clrs.append(classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "# Do 5 fold cross validation\n",
    "scores = cross_val_score(model, X_test, y_test, cv=5)\n",
    "print(round(scores[0],2)*100,\"% mean cross validation score with std \", round(scores.std(),4)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6c170-070b-4d15-a516-b0b6ce6d9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    TP = True positive   FP = False positive\n",
    "    TF = True negative   FN = False negative\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1-score = (2*recall*precision)/(recall+precision)\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    \n",
    "\"\"\"\n",
    "# Normalize confusion matrix\n",
    "cms = cms / cms.sum(axis=1)\n",
    "\n",
    "plt.subplots(figsize=(10,5))\n",
    "sns.heatmap(cms, annot=True,\n",
    "           fmt=\".2f\",\n",
    "           xticklabels = labels,\n",
    "           yticklabels = labels)\n",
    "\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "#plt.savefig(\"CM\", dpi = 1200)\n",
    "plt.show()\n",
    "\n",
    "print(clrs[-1])\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc04b8f8-5515-4778-a2ce-c9d1019a159f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_670/2016116849.py:85: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, signal = wavfile.read(path)\n",
      "/tmp/ipykernel_670/2016116849.py:96: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  _, test_sample = wavfile.read(f\"./predict/{audioname}.wav\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clean_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviisi_t\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m audio_sample \u001b[38;5;241m=\u001b[39m read_wav(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./predict/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number you said was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m Audio(audio_sample, rate\u001b[38;5;241m=\u001b[39mfs)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mpredict_input\u001b[0;34m(audioname, model, scaler, length)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_input\u001b[39m(audioname, model, scaler, length):\n\u001b[1;32m     96\u001b[0m     _, test_sample \u001b[38;5;241m=\u001b[39m wavfile\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./predict/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudioname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m     clean \u001b[38;5;241m=\u001b[39m \u001b[43mclean_data\u001b[49m(test_sample)\n\u001b[1;32m     98\u001b[0m     features \u001b[38;5;241m=\u001b[39m MFCC(clean, fs)\n\u001b[1;32m     99\u001b[0m     features[features\u001b[38;5;241m!=\u001b[39mfeatures] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_data' is not defined"
     ]
    }
   ],
   "source": [
    "# This sample is from someone whose voice was used to train the model\n",
    "filename = \"viisi_t\"\n",
    "audio_sample = read_wav(f\"./predict/{filename}.wav\")\n",
    "\n",
    "prediction = predict_input(filename,model,scaler, X_train.shape[1])\n",
    "print(f\"The number you said was {prediction}\")\n",
    "\n",
    "Audio(audio_sample, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6ad28-09c8-47d2-909a-91b05cfaa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sample is from someone whose voice was used to train the model\n",
    "\n",
    "filename = \"test7\"\n",
    "audio_sample = read_wav(f\"./predict/{filename}.wav\")\n",
    "\n",
    "prediction = predict_input(filename,model,scaler, X_train.shape[1])\n",
    "print(f\"The number you said was {prediction}\")\n",
    "\n",
    "Audio(audio_sample, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475f167-b733-4b81-a60a-a5cea259208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sample is from someone whose voice was used to train the model\n",
    "\n",
    "filename = \"kolme_t\"\n",
    "audio_sample = read_wav(f\"./predict/{filename}.wav\")\n",
    "\n",
    "prediction = predict_input(filename,model,scaler, X_train.shape[1])\n",
    "print(f\"The number you said was {prediction}\")\n",
    "\n",
    "Audio(audio_sample, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497221a-6376-4ea2-a9c7-175782b29b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf13c7-34ac-425c-878c-bf14ad423499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
